<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[mysql字段类型binary和varbinary]]></title>
    <url>%2F2017%2F09%2F13%2Fmysql-binary%2F</url>
    <content type="text"><![CDATA[以前都没用过binary和varbinary类型，这边存中文用这两个类型 mysql版本为5.7 官网地址：https://dev.mysql.com/doc/refman/5.7/en/binary-varbinary.html binary、varbinary类型和char、varchar类似，除了它们是存储二进制数据，而不是非二进制字符串。也就是说它们包含字节而不是字符串。这意味着，它们有二进制字符集和校对规则，并且基于值中的字节数值比较和排序。 允许的最大长度和char、varchar一样，除了一个是字节长度，一个是字符长度。 binary和varbinary数据类型与char binary和varchar binary数据类型不同。对于后一种，binary属性不会把列当成二进制字符列。相反，它会使用列字符集的二进制(_bin)校对规则，列本身存储非二进制字符串而不是二进制字节串。比如，char(5) binary是char(5) CHARACTER SET latin1 COLLATE latin1_bin，假设默认的字符集为latin1。区别于binary(5)，存储的是5字节二进制字符，二进制字符集和校对规则。关于更多二进制字符和非二进制字符串有二进制校对规则的区别，查看Section 10.1.8.5, “The binary Collation Compared to _bin Collations”。 如果严格sql模式没有开启，并且你还给binary或varbinary列设置了超出列最大长度的值，则值会被截断至合适长度并且产生一个警告。对于缩减的例子，你可以通过开启严格sql模式来禁止插入值，从而产生一个错误（而不是一个警告）。可以查看Section 5.1.8, “Server SQL Modes”。 当存储binary值时，它们会被填充值右填充到指定长度。填充值为0x00(0字节)。插入时右填充0x00，查询时不删除尾随字节。所有字节在比较时都有意义，包括order by和distinct操作。0x00字节和空格在比较时是不同的，0x00小于空格。 比如：对于binary(3)列，插入’a ‘时会变成’a \0’。插入’a\0’会变成’a\0\0’。查询时插入的值保持不变。 对于varbinary，插入不会填充，查询时不会去除任何字节。所有字节在比较时都有意义，包括order by和distinct操作。0x00字节和空格在比较时是不同的，0x00小于空格。 还有尾随的填充字节被删掉或者比较时忽略它们的例子，如果列有个唯一索引，插入的列值只有尾随字节数不同才会导致重复键错误。比如，如果表包含’a’，则尝试存储’a\0’将会引发一个重复键错误。 如果你打算用binary类型存储二进制数据，应该仔细考虑上面说的填充和删除特性，确保你检索的值和存储的值完全一样。下面的例子说明binary值的0x00填充是如何影响列值比较： mysql&gt; CREATE TABLE t (c BINARY(3)); Query OK, 0 rows affected (0.01 sec) mysql&gt; INSERT INTO t SET c = &apos;a&apos;; Query OK, 1 row affected (0.01 sec) mysql&gt; SELECT HEX(c), c = &apos;a&apos;, c = &apos;a\0\0&apos; from t; +--------+---------+-------------+ | HEX(c) | c = &apos;a&apos; | c = &apos;a\0\0&apos; | +--------+---------+-------------+ | 610000 | 0 | 1 | +--------+---------+-------------+ 1 row in set (0.09 sec) 如果检索的值必须和没有填充存储的值一样，那么可能用varbinary或者blog数据类型的一种比较合适。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[学会偷懒]]></title>
    <url>%2F2017%2F07%2F23%2Flazy%2F</url>
    <content type="text"><![CDATA[我觉得每个工程师都应该学会”偷懒“，通过各种工具来减少很多无意义的步骤或者工作。 公司的mac没货了，好像是入职的应届生太多，只能再等个两三那个月，真是太悲剧了。不过发的Thinkpad也还不错，起码开关机挺快的。触摸板确实没有mac的好用啊。 我们的产品主要是个app，调试测试什么的就需要手机连pc的代理，所以需要机器的ip。windows每次都要打开“运行”，输入“cmd”唤起命令行，然后输入ipconfig，并且在一堆信息中找到ipv4地址（在mac上也一样），比较不方便，所以想着能一键获取ip。 当然写个windows可执行文件应该也行，可是不会，所以就用python吧。 123456789101112131415import socketimport timedef get_host_ip(): try: s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) s.connect((&apos;8.8.8.8&apos;, 80)) ip = s.getsockname()[0] finally: s.close() return ipip = get_host_ip()print(ip)time.sleep(30) 装个python，网上一大堆资料，把上面的python脚本放到桌面，执行后就能显示本机内网ip了。其实就是利用python创建的socket，获取自身包里面的IP。]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[memcached的内存管理总结]]></title>
    <url>%2F2017%2F06%2F19%2Fmemcached%2F</url>
    <content type="text"><![CDATA[为什么memcached（文中简写mc）的内存还有空余，而我设置的key还是会被挤掉呢？（文中memcached都指1.4.37版本） 安装首先是安装，网上一大堆，需要注意的是依赖libevent 启动memcached -h可以查看对应的启动参数，这里介绍几个常用的： 123456789101112131415161718192021-p &lt;num&gt; TCP port number to listen on (default: 11211) 指定端口号，默认是11211-l &lt;addr&gt; interface to listen on (default: INADDR_ANY, all addresses) &lt;addr&gt; may be specified as host:port. If you don&apos;t specify a port number, the value you specified with -p or -U is used. You may specify multiple addresses separated by comma or by using -l multiple times 绑定地址，比如只允许本地访问 -l 127.0.0.1-d run as a daemon 守护进程运行-u &lt;username&gt; assume identity of &lt;username&gt; (only when run as root) 指定用户运行-m &lt;num&gt; max memory to use for items in megabytes (default: 64 MB) 分配的内存，默认64m-M return error on memory exhausted (rather than removing items) 内存满后是否返回错误或者移除item-vv very verbose (also print client commands/responses) 可以看到slab分配种类-I Override the size of each slab page. Adjusts max item size (default: 1mb, min: 1k, max: 128m) 指定slab的大小，默认1m-n &lt;bytes&gt; minimum space allocated for key+value+flags (default: 48) 默认的key+value+flags大小-f &lt;factor&gt; chunk size growth factor (default: 1.25) chunk增长的倍率 所以启动可以这样 memcached -l 127.0.0.1 -P /tmp/memcached.pid -u www -m 100 -d 几个名词mc内存的几个名词：slab：内存块，mc一次申请内存的最小单位，默认1m，可以用-I参数修改page: 分配给Slab的内存空间chunk: 一个slab会被划分成几个相同大小的chunkitem：我们需要保存的数据，一个chunk保存一个item，item主要存储缓存的key、value、key的长度、value的长度、缓存的时间等信息slabclass：slab的种类，mc会根据slab划分chunk的大小不一样来分成不同种类的slabSlab是一个内存块，它是memcached一次申请内存的最小单位。在启动memcached的时候一般会使用参数-m指定其可用内存，但是并不是在启动的那一刻所有的内存就全部分配出去了，只有在需要的时候才会去申请，而且每次申请一定是一个slab。如图：图中几个错误的地方：在我的机器上chunk size：96*f^(n-1)classes分了42种，item不仅仅存储了key和value slab分配的策略启动时可以用-vv查看slab的分配策略，例如：123456789101112131415161718192021222324252627282930313233343536373839404142slab class 1: chunk size 96 perslab 10922slab class 2: chunk size 120 perslab 8738slab class 3: chunk size 152 perslab 6898slab class 4: chunk size 192 perslab 5461slab class 5: chunk size 240 perslab 4369slab class 6: chunk size 304 perslab 3449slab class 7: chunk size 384 perslab 2730slab class 8: chunk size 480 perslab 2184slab class 9: chunk size 600 perslab 1747slab class 10: chunk size 752 perslab 1394slab class 11: chunk size 944 perslab 1110slab class 12: chunk size 1184 perslab 885slab class 13: chunk size 1480 perslab 708slab class 14: chunk size 1856 perslab 564slab class 15: chunk size 2320 perslab 451slab class 16: chunk size 2904 perslab 361slab class 17: chunk size 3632 perslab 288slab class 18: chunk size 4544 perslab 230slab class 19: chunk size 5680 perslab 184slab class 20: chunk size 7104 perslab 147slab class 21: chunk size 8880 perslab 118slab class 22: chunk size 11104 perslab 94slab class 23: chunk size 13880 perslab 75slab class 24: chunk size 17352 perslab 60slab class 25: chunk size 21696 perslab 48slab class 26: chunk size 27120 perslab 38slab class 27: chunk size 33904 perslab 30slab class 28: chunk size 42384 perslab 24slab class 29: chunk size 52984 perslab 19slab class 30: chunk size 66232 perslab 15slab class 31: chunk size 82792 perslab 12slab class 32: chunk size 103496 perslab 10slab class 33: chunk size 129376 perslab 8slab class 34: chunk size 161720 perslab 6slab class 35: chunk size 202152 perslab 5slab class 36: chunk size 252696 perslab 4slab class 37: chunk size 315872 perslab 3slab class 38: chunk size 394840 perslab 2slab class 39: chunk size 493552 perslab 2slab class 40: chunk size 616944 perslab 1slab class 41: chunk size 771184 perslab 1slab class 42: chunk size 1048576 perslab 1 这是启动时mc会分配的slab种类，实际上，这只是个分配策略，预定义好可能使用的slab大小，并没有真正去申请内存空间，只有当实际数据添加时，才会有slab的内存申请。当数据进来时Memcached会选择一个大于等于最接近的slab来进行存储。比如第一次往mc添加一个10字节item时，mc会根据item大小，选择合适的slab大小如class 1，然后申请内存空间，用去一个chunk，从这可以看出，剩余的86字节确实浪费了。剩下的10921个chunk供下次有适合大小item时使用，当我们用完10922个chunk后，如果再有类似item进来，mc会再申请空间生成一个class 1的slab。默认一个slab的大小是1m，也就是1024x1024= 1048576字节，class 1的chunk数是1048576/96= 10922，取整。 chunk的大小计算公式： (default_size+item_size)*f^(i-1) + CHUNK_ALIGN_BYTES i是分类，比如slab class 1default_size 是启动时-n参数的值，默认48字节item_type：item结构体的长度，这个版本的是48字节f为factor，是增长倍率，默认为1.25 -f参数指定CHUNK_ALIGN_BYTES是修正值，为了保证chunk的大小是某个值的整数倍，在64位系统里，该值为8slabs.c中slabs_init函数（确定chunk大小，初始化slab class的描述符）的代码： 123/* Make sure items are always n-byte aligned */ if (size % CHUNK_ALIGN_BYTES) size += CHUNK_ALIGN_BYTES - (size % CHUNK_ALIGN_BYTES); 所以，slab class 1的chunk size = 48 + 48 = 96（8的倍数）slab class 2的chunk size = 96 x 1.25 = 120（8的倍数）slab class 3的chunk size = 120 x 1.25 = 150（不是8的倍数）则按照上面的公式size += 8 - （150 % 8） 得出size=152以此类推 回到开头，为什么mc的内存还有空余，而我设置的key还是会被挤掉呢？因为大量长度不规则的key，导致新申请了很多slab，占满了内存（这里占满，并不是说实实在在的内存使用，而是有点像上自习占座一样，虽然座位上没人，但是座位已经被定了），此时，新来一个item，如果适合的slab已经满了，mc并不会将这个item塞到大一点的slab，而是另外申请一个相同大小的slab，但是分配给mc的内存已经不够了，这时候就会挤掉原来slab中的数据，如果不想挤掉原来的，可以加-M参数。timyang 总结了几点： 尽量不用随机字符串作为key，使用定值，这样占用空间大小相对固定。估算空间大小时候请用slab size计算，不要按value长度去计算。过期的不要和不过期的数据存在一起，否则不过期的可能被踢。 mc过期策略mc的缓存过期机制，并不会将内存释放给系统，而是将该内存标注为可用状态。并且有以下几种策略： 查询时检查过期 创建item的时候检查过期 执行flush命令，将所有item设置为失效 lru爬虫，mc默认时关闭的。一个单独的线程，清理失效的item。（redis也有这种机制） LRU淘汰。先从LRU链表找有没有恰好过期的空间，有就用这个。如果没有过期空间，则分配新的空间。如果分配失败，那么往往是内存用光，则从LRU链表中把最旧的即使没过期的item淘汰掉，空间分给新的item。LRU链表插入缓存item的时候有先后顺序，所以淘汰一个item也是从尾部进行，也就是淘汰最早的item。 需要注意的一点：如果设置过期时间超过30天，实际效果为1s后过期。 参考资料：https://www.zybuluo.com/phper/note/443547http://chenzhenianqing.cn/articles/1329.htmlhttp://calixwu.com/2014/11/memcached-yuanmafenxi-neicunguanli.htmlhttp://blog.csdn.net/initphp/article/details/44680115https://www.dexcoder.com/selfly/article/2248http://weibo.com/p/230418c019b4be0102w0tj?from=page_100505_profile&amp;wvr=6&amp;mod=wenzhangmodhttps://timyang.net/data/memcached-lru-evictions/]]></content>
      <categories>
        <category>缓存</category>
      </categories>
      <tags>
        <tag>memcached</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[curl超时导致进程假死]]></title>
    <url>%2F2017%2F05%2F27%2Fcurl%2F</url>
    <content type="text"><![CDATA[其实主要是如何去查看进程相关的东西 很多时候的进程假死都是网络超时导致的，比如curl。curl的底层库是libcurl，它有以下几个对时间控制的设置： 123456CURLOPT_FTP_RESPONSE_TIMEOUT: No default (indefinite)CURLOPT_TIMEOUT: No default (indefinite)CURLOPT_TIMEOUT_MS: No default (indefinite)CURLOPT_CONNECTTIMEOUT: Defaults to 300 secondsCURLOPT_CONNECTTIMEOUT_MS: No defaultCURLOPT_ACCEPTTIMEOUT_MS: Defaults to 60000 ms 其中 CURLOPT_ACCEPTTIMEOUT_MS是和ftp相关的，CURLOPT_CONNECTTIMEOUT是连接的超时设置。可以从https://curl.haxx.se/libcurl/c/curl_easy_setopt.html去查看相关参数。可以看出，默认情况下，curl是不会超时的，假如连上服务，curl会一直保持连接。对于php，可以从http://cn2.php.net/manual/zh/function.curl-setopt.php 查看。我们来模拟一下场景：在一台机器a上用nc开一个123的端口去等待连接然后在另一台机器b上用curl命令连接可以看到它会阻塞在那，此时用strace命令查看curl进程，看该进程到底在干啥发现curl一直在用poll并且超时。通常来说，我们查问题是从strace开始看的，所以找到该处，看到是poll，并且超时，而它打开的文件描述符fd是3，那么接下来用lsof查看该进程打开的所有fd找到fd是3的一行，图中是3u，看到是一个tcp连接，连接的对方ip正是机器a的ip。 curl能设置毫秒级别的超时吗？虽然curl提供了相关ms参数设置，但实际上却是还有问题，具体参考鸟哥的这篇文章http://www.laruence.com/2014/01/21/2939.htmlphp官方文档也对CURLOPT_TIMEOUT_MS给出了说明： 设置cURL允许执行的最长毫秒数。 如果 libcurl 编译时使用系统标准的名称解析器（ standard system name resolver），那部分的连接仍旧使用以秒计的超时解决方案，最小超时时间还是一秒钟。 还是在机器a上起123端口，然后机器b上用php去测试 12345678910111213141516171819202122&lt;?phpfunction test($url)&#123; $ch = curl_init(); curl_setopt($ch, CURLOPT_RETURNTRANSFER, 1); curl_setopt($ch, CURLOPT_URL, $url); curl_setopt($ch, CURLOPT_HEADER, true); curl_setopt($ch, CURLOPT_USERAGENT, "Mozilla/4.0 (compatible; MSIE 5.01; Windows NT 5.0)"); curl_setopt($ch, CURLOPT_TIMEOUT_MS, 10); $result = curl_exec($ch); var_dump(curl_error($ch)); curl_close($ch); return $result;&#125; $url = 'http://x.x.x.x:123';$start = gettimeofday(true);$l = test($url);var_dump($l);$time = gettimeofday(true) - $start;var_dump($time); 执行返回：Timeout was reached，并且在a上没接收到任何请求一种是设置CURLOPT_NOSIGNAL 1curl_setopt($ch, CURLOPT_NOSIGNAL, 1); 此时再执行，会发现a上确实接收到请求了，但是curl超时最小1秒，这和官网上说的一致，也就是设置毫秒无效。 另外一种是启动libcurl的c-ares，这是异步dns解析，一般linux机器上安装curl都不会启动该功能，可以在自己机器上用curl –version查看下是否有c-ares标志，如需启用需要下载相关安装包，并且重新编译libcurl，可以参考https://www.haiyun.me/archives/1068.html 参考资料： https://stackoverflow.com/questions/10308915/php-default-curl-timeout-value]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[php的文件锁flock总结]]></title>
    <url>%2F2017%2F05%2F03%2Fflock%2F</url>
    <content type="text"><![CDATA[先从应用方面，之后会从操作系统方面深入理解 如果两个进程同时写一个文件，那么两个进程写的内容势必会乱掉，那么如何保证内容不乱呢，加锁。PHP加锁的函数为flock，该函数有3个参数： 文件指针； 锁类型，LOCK_SH共享锁，LOCK_EX独占锁，LOCK_UN释放锁。加上LOCK_NB将不会阻塞，而是立即返回。比如LOCK_SH|LOCK_NB； wouldblock，是个引用变量，一般不会用到，可以传入一个变量，然后打印该变量看函数赋的是什么值； LOCK_SH共享锁，用在读取程序上；LOCK_EX独占锁，用在写入程序上； 读取文件 如果在lock1.php读取一个文件时（未加锁），lock2.php往里面写（没有加锁），那么lock1.php有可能读取脏数据，即读到lock2.php写入的数据； 在lock1.php读取一个文件时（加了LOCK_SH锁），lock2.php往里面写（没有加锁），那么lock1.php还是会读取脏数据，即读到lock2.php写入的数据； lock1.php: 123456789101112131415&lt;?php$f = fopen('test.txt', 'r');if ( flock($f, LOCK_SH) ) &#123; while (!feof($f)) &#123; $contents = fread($f, 1); echo $contents.chr(10); usleep(100000); &#125; flock($f, LOCK_UN);&#125; else &#123; echo 'no';&#125;fclose($f); lock2.php: 123456&lt;?php$f = fopen('test.txt', 'a+');$re = fwrite($f, 'ok');var_dump($re);fclose($f); 3.如果在lock1.php读取一个文件时（加了LOCK_SH锁），lock2.php往里面写（加上LOCK_EX锁），那么lock2.php会阻塞直到lock1.php读取完毕后再写入 lock1.php 1234567891011121314&lt;?php$f = fopen('test.txt', 'r');if (flock($f, LOCK_SH)) &#123; while (!feof($f)) &#123; $contents = fread($f, 2); echo $contents.chr(10); usleep(10000); &#125;&#125; else &#123; echo 'no lock'.chr(10);&#125;fclose($f); lock2.php 123456789101112&lt;?php$f = fopen('test.txt', 'a+');if ( flock($f, LOCK_EX) ) &#123; //if ( flock($f, LOCK_EX|LOCK_NB) ) &#123; 不会阻塞，立即返回 fwrite($f, 'ok'); flock($f, LOCK_UN);&#125; else &#123; echo 'no';&#125;fclose($f); 写入文件 如果lock1.php写一个文件时（未加锁），lock2.php读取该文件（未加锁），那么lock2.php会读到脏数据 如果lock1.php写一个文件时（加上LOCK_EX锁），lock2.php读取该文件（未加锁），那么lock2.php还是会读到脏数据 如果lock1.php写一个文件时（加上LOCK_EX锁）, lock2.php读取该文件（加了LOCK_SH锁），那么lock2.php会等待lock1.php写完并且释放锁后读取。 lock1.php 1234567891011&lt;?php$f = fopen('test.txt', 'a+');if (flock($f, LOCK_EX)) &#123;for ($i = 0; $i&lt;1000; $i++) &#123; fwrite($f, $i.chr(10)); sleep(1);&#125;&#125;fclose($f); lock2.php 12345678910111213&lt;?php$f = fopen('test.txt', 'r');if (flock($f, LOCK_SH|LOCK_NB)) &#123;while (!feof($f)) &#123; $re = fread($f, 2); echo $re.chr(10); usleep(1000);&#125;&#125; else &#123; echo 'file locked'.chr(10);&#125; 如果多个进程同时写文件，为了避免错乱，那么每个进程都需要用flock来尝试获取锁，用LOCK_EX排它锁。]]></content>
      <categories>
        <category>php</category>
      </categories>
      <tags>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysqlnd驱动]]></title>
    <url>%2F2017%2F02%2F15%2Fmysqlnd%2F</url>
    <content type="text"><![CDATA[了解下mysqlnd驱动 翻译的是官方文档http://php.net/manual/zh/mysqlnd.overview.php php5.3以前，默认使用的都是libmysqlclient(MySQL client server library)，5.3之后，mysqlnd(mysql native driver)已经内置于php源代码中，并且官方强烈建议使用这个驱动。虽然它是作为php扩展被编写，但是需要注意的是，它不提供新API给php程序员。连接mysql的API是由mysql扩展，由mysqli和PDO MYSQL提供。这些扩展现在可以用mysqlnd与mysql server通信。因此，你不应该认为mysqlnd是一个API。 mysqlnd比MySQL Client Library多几个优点 旧的MySQL Client Library是由MySQL AB（现在是oracle组织）写的，所以是在mysql许可证下发行的。这最终导致mysql支持在php中默认被禁用。但是，mysqlnd已经作为php项目的一部分被开发，是在php许可证下发行，这消除了过去存在的许可问题。 同时，在过去，你需要根据libmysqlclient的副本构建mysql数据库扩展。意味着，你在安装php的机器上需要安装mysql。并且，PHP应用运行时，mysql的扩展会调用libmysqlclient文件，所以该文件需要在你的系统上被安装。而用mysqlnd将不会有这种情况，因为它是作为标准分发的一部分了。所以你不需要安装一个mysql来构建php或者运行php数据库应用。 因为mysqlnd作为php扩展被编写，所以它能够和php工作紧密结合。这在效率上会有收益，特别是来自内存的使用，作为驱动在php内存管理系统中使用。它同样支持php内存限制。使用mysqlnd比libmysqlclient有更好的性能，它总是保证最有效的使用内存。一个例子是，当用MySQL Client Library，每一行都会在内存中存储两次，而用mysqlnd只存储一次。 注意：内存使用 因为mysqlnd用的是php的内存管理系统，它的内存使用会被 memory_get_usage()函数追踪到。而这对libmysqlclient来说是不可能的，因为它用的是c函数malloc(). 特殊功能mysqlnd提供一些MySQL Client Library没有的特殊功能： 改进了持久连接 特殊方法mysqli_fetch_all() 性能统计调用： mysqli_get_cache_stats(), mysqli_get_client_stats(), mysqli_get_connection_stats() 性能统计工具在识别性能瓶颈上被证明非常有用。当用mysqli扩展时，mysqlnd同样提供持久连接。 ssl支持从php5.3.3开始，mysqlnd意境支持ssl 压缩协议支持php5.3.2 mysqlnd支持压缩的客户端服务协议。在5.3.0和5.3.1中还不支持。扩展比如ext/mysql,ext/mysqli用mysqlnd，同样可以利用此功能。注意pdo_mysql不支持压缩当和mysqlnd一起用时。 命名管道支持windows的命名管道支持在php5.4.0被增加]]></content>
      <categories>
        <category>php</category>
      </categories>
      <tags>
        <tag>mysql php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[The innoDB buffer pool]]></title>
    <url>%2F2017%2F01%2F04%2FbufferPool%2F</url>
    <content type="text"><![CDATA[最近和DBA打交道，提到了InnoDB的buffer pool，所以想了解下这个概念，最好的方式当然是翻译官方文档。 文档版本是5.7. 官网地址：https://dev.mysql.com/doc/refman/5.7/en/innodb-buffer-pool.html The InnoDB Buffer PoolInnoDB维持了一个存储空间叫buffer pool，在内存里缓存数据和索引。知道InnoDB的buffer pool如何工作，并且经常利用它访问内存中的数据是一个很重要的mysql访问调优方式。 你可以配置各种各样的InnoDB buffer pool方式来提升性能。 最理想的，你设置的buffer pool大小和实际的值一样，留下足够的内存给服务器上的其他程序运行，从而没有超出页。buffer pool越大，InnoDB变的越像内存数据库，只从磁盘读取一次数据，然后在之后的读取中从内存中访问数据。查看Section 15.6.3.2, “Configuring InnoDB Buffer Pool Size” 在64位系统大内存中，你可以切分buffer pool为多个部分，在并发操作中降低对内存结构的竞争。更多细节，查看Section 15.6.3.3, “Configuring Multiple Buffer Pool Instances”. 你可以经常访问内存中数据，尽管有突然的操作高峰比如备份或者报告。更多细节，查看Section 15.6.3.4, “Making the Buffer Pool Scan Resistant”. 你可以控制InnoDB何时和如何提供预读请求，异步预取很快会被用到的页面进buffer pool。更多细节，查看Section 15.6.3.5, “Configuring InnoDB Buffer Pool Prefetching (Read-Ahead)”. 你可以控制当后台刷新脏页面时，InnoDB是否动态调整基于工作量的刷新比率。更多细节，查看Section 15.6.3.6, “Configuring InnoDB Buffer Pool Flushing”. 你可以微调InnoDB buffer pool刷新行为部分来提高性能。更多细节，查看Section 15.6.3.7, “Fine-tuning InnoDB Buffer Pool Flushing”. 你可以配置InnoDB在服务重启后，如何保护当前buffer pool状态，避免冗长的预热期。你也可以保存当前的buffer pool状态，在服务运行的同时。更多细节，查看Section 15.6.3.8, “Saving and Restoring the Buffer Pool State”. InnoDB Buffer Pool LRU 算法InnoDB管理一个buffer pool列表，用一个最少最近使用(LRU)算法的变体。当房间需要增加一个新页面进pool时，InnoDB会清除最少最近用的页面，增加新页面到列表中间。这个“中点插入策略”按照以下两个子列表对待列表： 在头部，一个新或者young页面子列表是最近访问的 在尾部，一个旧页面子列表是最少最近访问的 这个算法使得在新子列表中页面能被大量查询到。旧的子列表包含最少使用页面；这些页面是清除的候选。 LRU算法默认按照以下几点操作： 3/8的buffer pool专门给旧的子列表用 列表中点是新子列表尾部遇到旧子列表头部的边界 当InnoDB读取一个页面进buffer pool时，起初会被插入到中点（旧子列表的头部）。这个页面能被读取是因为它包含在用户的特殊操作中，比如一个SQL查询，或者是在InnoDB的自动预读取操作部分。 随着数据库的操作，在buffer pool中未被访问的页面通过向列表尾部移动而“老化”。新旧子列表中的页面随着其他页面变新而变旧。旧子列表中页面也随着页面被插入到中点而变旧。最终，很长时间没被使用的页面到达旧列表尾部而被清除。 默认，被查询的页面会立即移动到新子列表，意味着它们将会在很长一段时间内留在buffer pool。一个表扫描（例如一个mysqldump操作，或者没有where的select语句）会带很大的数据进入buffer poll，然后清除大量的旧数据，即使这个新数据从来不会被用。类似的，后台进程预读加载的页面，只有被移到新列表的头部才会被访问到。这些情况会经常推送有用的页面到旧子列表，然后它们成为清除的对象。关于这些行为的更多信息，查看Section 15.6.3.4, “Making the Buffer Pool Scan Resistant”和Section 15.6.3.5, “Configuring InnoDB Buffer Pool Prefetching (Read-Ahead)”. InnoDB标准监控输出包含buffer pool和内存部分的几个领域，这些从属于buffer pool LRU算法。更多细节查看Section 15.6.3.9, “Monitoring the Buffer Pool Using the InnoDB Standard Monitor”. InnoDB Buffer Pool 配置选项几个影响InnoDB buffer pool不同部分的配置选项。 innodb_buffer_pool_size指定buffer pool的大小。如果buffer pool比较小，而你有充足的内存，那么把buffer pool增大点可以减少查询访问InnoDB表的磁盘I/O操作，从而提升性能。在mysql的5.7.5，innodb_buffer_pool_size设置是动态的，不用重启服务你就可以配置它。查看Section 15.6.3.2, “Configuring InnoDB Buffer Pool Size”. innodb_buffer_pool_chunk_size定义了Innodb buffer pool 改变操作的块大小。查看Section 15.6.3.2, “Configuring InnoDB Buffer Pool Size” innodb_buffer_pool_instances划分buffer pool为用户指定的几个单独部分，每一个都有自己的LRU列表和相近的数据结构，这样在并发的内存读写操作中减少竞争。这个选项只有在你设置innodb_buffer_pool_size大于1GB时才生效。你指定的总大小会被划分给所有的buffer polls。为了最高的效率，可以指定一个innodb_buffer_pool_instances和innodb_buffer_pool_size的组合，这样每一个buffer pool实例都至少有1g。查看Section 14.9.2.2, “Configuring Multiple Buffer Pool Instances”. innodb_old_blocks_pct指定InnoDB给旧子列表块用的buffer pool近似百分比。值范围为5到95。默认值为37（也就是3/8的pool）。查看Section 15.6.3.4, “Making the Buffer Pool Scan Resistant”. innodb_old_blocks_time指定一个页面插入到旧子列表后必须停留多少ms，当它第一次被访问移到新子列表前。如果值是0，那么被移到旧子列表的页面将会立即移动到新子列表，当它第一次被访问的时候，无论插入后访问发生了多久。如果值大于0，页面会停留在旧子列表知道一个访问发生，至少第一次访问后许多ms。比如，值是1000会使页面停留在旧子列表1秒在第一次访问之后，移动到新子列表之前。 设置innodb_old_blocks_time值超过0可以防止一次表扫描扫大量的新子列表，只为了这次扫描。一次页面扫描读取行被快速连续访问多次，但是之后这个页面却是没用的。如果innodb_old_blocks_time设置的值比处理页面的时间大，那么在旧子列表的和该到列表尾部的页面将被很快的清除。这样，只被一次表扫描用的页面不会对新子列表中的大量使用的页面造成损害。 innodb_old_blocks_time可以在运行时设置，所以你可以在执行诸如表扫描和下载操作的时候暂时改变它： SET GLOBAL innodb_old_blocks_time = 1000; ... perform queries that scan tables ... SET GLOBAL innodb_old_blocks_time = 0; 这个策略并不会执行，如果你的意图是想通过充满一个表的内容来热启动buffer pool。比如，基准测试经常在服务启动时做一个表或者索引扫描，因为当用了一段时间之后，数据通常都在buffer pool里面。在这种情况，把innodb_old_blocks_time设为0，至少等到热启动完成。查看Section 15.6.3.4, “Making the Buffer Pool Scan Resistant”. innodb_read_ahead_threshold控制线性预读的灵敏度，InnoDB经常用来预读取页面进buffer pool。查看Section 15.6.3.5, “Configuring InnoDB Buffer Pool Prefetching (Read-Ahead)”. innodb_random_read_ahead为预读取页面进buffer pool启动随机预读技术。随机预读技术是基于已经存在buffer pool的也看来预言将会被用到的页面，不理会那些页面被读取的顺序。innodb_random_read_ahead默认是关闭的。查看Section 15.6.3.5, “Configuring InnoDB Buffer Pool Prefetching (Read-Ahead)”。 innodb_adaptive_flushing指定是否自动调整刷新脏页面的比率，基于在工作中的buffer pool。自动调整刷新比率是想要防止I/O操作的爆发。这个设定是默认开启的。查看Section 15.6.3.6, “Configuring InnoDB Buffer Pool Flushing”. innodb_adaptive_flushing_lwm当adaptive flushing启用时，低水位线，相当于redo log所能容纳的百分比。查看Section 15.6.3.7, “Fine-tuning InnoDB Buffer Pool Flushing” innodb_flush_neighbors规定从buffer pool刷新页面是否也刷新其他dirty pages，在同样extent范围里。查看Section 15.6.3.7, “Fine-tuning InnoDB Buffer Pool Flushing”. innodb_flushing_avg_loopsinnoDB保留之前计算的刷新状态快照的迭代次数，控制adaptive flushing回应改变工作量的速度。查看Section 15.6.3.7, “Fine-tuning InnoDB Buffer Pool Flushing” innodb_lru_scan_depth一个影响flush操作buffer pool的算法和启发式。主要关注i/o密集型工作量性能。具体来说，每一个buffer pool实例，page_cleaner线程扫描寻找脏页面刷新有多深入buffer pool LRU的列表。查看Section 15.6.3.7, “Fine-tuning InnoDB Buffer Pool Flushing”. innodb_max_dirty_pages_pctInnoDB会尝试从buffer pool中刷新数据，使得脏页面的占比不回超过这个值。指定一个从0到99的整数。默认值为75.查看Section 15.6.3.6, “Configuring InnoDB Buffer Pool Flushing”. innodb_max_dirty_pages_pct_lwm预刷新的脏页面低水位控制脏页面比例。默认值0来使预刷新行为完全无效。查看Section 15.6.3.7, “Fine-tuning InnoDB Buffer Pool Flushing”. innodb_buffer_pool_filename指定文件名字，该文件保存innodb_buffer_pool_dump_at_shutdown和innodb_buffer_pool_dump_now产生的表空间ID和页面ID。查看Section 15.6.3.8, “Saving and Restoring the Buffer Pool State” innodb_buffer_pool_dump_at_shutdown指明当mysql宕机的时候是否记录缓存在buffer pool的页面，以在下次重启时缩短预热过程。查看Section 15.6.3.8, “Saving and Restoring the Buffer Pool State” innodb_buffer_pool_load_at_startup指定在mysql启动时，buffer pool预热自动加载早些时候加载的页面.通常和innodb_buffer_pool_dump_at_shutdown一起用。查看Section 15.6.3.8, “Saving and Restoring the Buffer Pool State” innodb_buffer_pool_dump_now立即记录缓存在buffer pool的页面。查看Section 15.6.3.8, “Saving and Restoring the Buffer Pool State” innodb_buffer_pool_load_now立即预热buffer pool加载一些数据页面，不等mysql重启。在基准测试中将缓存恢复到已知状态很有用，或者是使mysql运行报表或维护查询后恢复正常工作负载。通常和innodb_buffer_pool_dump_now一起用。查看Section 15.6.3.8, “Saving and Restoring the Buffer Pool State” innodb_buffer_pool_dump_pct指定每一个buffer pool读出下载最近用到的页面百分比。范围从1到100. 查看Section 15.6.3.8, “Saving and Restoring the Buffer Pool State” innodb_buffer_pool_load_abort中断由innodb_buffer_pool_load_at_startup或者innodb_buffer_pool_load_now触发的修复buffer pool内容的进程。查看Section 15.6.3.8, “Saving and Restoring the Buffer Pool State”]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[varchar和char区别]]></title>
    <url>%2F2016%2F10%2F27%2Fchar-varchar%2F</url>
    <content type="text"><![CDATA[翻译官方文档： https://dev.mysql.com/doc/refman/5.7/en/char.html char和varchar类型比较相似，但是在存储和取出有区别，在最大长度和是否在尾部保留空格也有区别。 char和varchar都有一个长度声明，定义了你想存储的最大字符数。比如，char(30)可以存储最多30个字符。 当创建表时，char列的长度会一直补足到你所声明的长度。长度可以从0到255。当存储char类型值时，会在右边补足空格直到指定长度。当取出char类型值时，尾部空格将会被移除，除非PAD_CHAR_TO_FULL_LENGTHsql模式被启用。 varchar列中的值是可变长的字符串。长度可以指定从0到65535。一个varchar的有效最大长度取决于最大行大小(65535字节，在各个列之间取)和所设置的字符。可以查看Section C.10.4, “Limits on Table Column Count and Row Size”。 相比于char，varchar会在数据值前缀增加1字节或者2字节长度。这个前缀的长度定义了值的字节数。如果值没有超过255字节，那么用1个字节存储长度；超过了则用2字节。 如果没有启用严格SQL模式，而你赋值给一个char或者varchar列超过了列的最大长度，那么这个值会被截取，然后生成一个警告。启用严格SQL模式后，然后产生一个错误，并且值不会被插入。查看Section 6.1.8, “Server SQL Modes”。 对于varchar类型列，超过列长的尾部空格会在插入前删除，然后产生一个警告，和当前所使用的SQL模式无关。对于char类型列，超过的空格会被默默的从插入的值中截取，也和当前所使用的SQL模式无关。 当存储varchar时，值不会被补充。尾部空格会被保留当存储和取出时，这符合标准SQL。 以下图表说明了char和varchar存储字符串的区别，char(4)和varchar(4)列（假设列用单字节字符串存储，比如latin1）。 Value CHAR(4) Storage Required VARCHAR(4) Storage Required ‘’ ‘ ‘ 4 bytes ‘’ 1 byte ‘ab’ ‘ab ‘ 4 bytes ‘ab’ 3 bytes ‘abcd’ ‘abcd’ 4 bytes ‘abcd’ 5 bytes ‘abcdefgh’ ‘abcd’ 4 bytes ‘abcd’ 5 bytes 上面表中最后一行，只有在严格SQL模式下才会出现。如果是非严格SQL模式，超过长度的值不会被存储，并且报错。 对于 InnoDB的 COMPACT, DYNAMIC 和COMPRESSED 行格式，如果列值长度大于等于768字节，char被当作可变长度对待，当是utf8mb4时，如果最大字节长度设置为超过3也会发生。例如，当被当作可变长度类型时，一个char列的值可能被选为off-page存储。查看更多信息，Section 15.11, “InnoDB Row Storage and Row Formats”。 如果值存入char(4)和varchar(4)列，从列中取出不会总是一样的，因为尾部空格会从char列中移除，并且无法复原。以下例子说明了这个差异： mysql&gt; CREATE TABLE vc (v VARCHAR(4), c CHAR(4)); Query OK, 0 rows affected (0.01 sec) mysql&gt; INSERT INTO vc VALUES (&apos;ab &apos;, &apos;ab &apos;); Query OK, 1 row affected (0.00 sec) mysql&gt; SELECT CONCAT(&apos;(&apos;, v, &apos;)&apos;), CONCAT(&apos;(&apos;, c, &apos;)&apos;) FROM vc; +---------------------+---------------------+ | CONCAT(&apos;(&apos;, v, &apos;)&apos;) | CONCAT(&apos;(&apos;, c, &apos;)&apos;) | +---------------------+---------------------+ | (ab ) | (ab) | +---------------------+---------------------+ 1 row in set (0.06 sec) char和varchar列的值会被排序和比较根据赋值给这个值的字符校对。 所有的mysql校对都是PADSPACE类型。这意味着所有的char,varchar和text值在被比较的时候，不会去考虑尾部空格。在这里说的比较不包含like模式匹配操作，like中尾部空格是很重要的。例如： mysql&gt; CREATE TABLE names (myname CHAR(10)); Query OK, 0 rows affected (0.03 sec) mysql&gt; INSERT INTO names VALUES (&apos;Monty&apos;); Query OK, 1 row affected (0.00 sec) mysql&gt; SELECT myname = &apos;Monty&apos;, myname = &apos;Monty &apos; FROM names; +------------------+--------------------+ | myname = &apos;Monty&apos; | myname = &apos;Monty &apos; | +------------------+--------------------+ | 1 | 1 | +------------------+--------------------+ 1 row in set (0.00 sec) mysql&gt; SELECT myname LIKE &apos;Monty&apos;, myname LIKE &apos;Monty &apos; FROM names; +---------------------+-----------------------+ | myname LIKE &apos;Monty&apos; | myname LIKE &apos;Monty &apos; | +---------------------+-----------------------+ | 1 | 0 | +---------------------+-----------------------+ 1 row in set (0.00 sec) 这对所有的mysql版本都一样，也不会对SQL模式所影响。 Note更多MYSQL字符和校对的信息，查看Section 11.1, “Character Set Support”。关于存储需要的额外信息，查看Section 12.8, “Data Type Storage Requirements”。 那些尾部补足字符除去或者忽略比较的情况，如果一个列有一个唯一索引，只有在尾部有补足字符时不同，报重复键错误。比如，一个表包含’a’，当试图存储’a ‘会引起一个重复键错误。(注释：唯一索引会忽略尾部空格)]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[守护进程]]></title>
    <url>%2F2016%2F08%2F08%2Fdaemon%2F</url>
    <content type="text"><![CDATA[守护进程的一些原理和方法。 首先来看几个概念： 守护进程：daemon，运行在后台的特殊进程，是生存期长的一种进程，它独立于控制终端并且周期性的执行某种任务或等待处理某些发生的事件。 前台进程：在多任务操作系统（诸如 UNIX/Linux）中，前台进程是用户当前与之交互的程序（例如，数据输入）。随着用户在程序之间切换，会导致这些程序在不同的时刻处于前台。在层叠的窗口环境中，前台进程是最前面的窗口。在命令行中，默认程序和命令都作为前台进程运行，要在后台运行，需要加&amp;符号。 进程组：一个或者多个进程的集合。每个进程组有一个组长进程 会话(session)：一个或多个进程组的集合。一个会话可以有一个控制终端，通常是终端设备。会话通常是一个登录进程创建的，创建会话的进程为会话首进程(session leader)，只有session leader才能控制终端。 那么，成为一个守护进程的关键是什么？ 脱离终端，不继承标准输入。脱离终端的目的是避免进程在运行过程中的信息在任何终端中显示，并且进程也不会被任何终端所产生的终端信息打断。 如何命令行启动一个后台进程 可以参考这篇Linux 守护进程的启动方法。这里简单说下里面的nohup，比如：nohup php 1.php 2&gt;&amp;1 &amp;nohup表示挂起，标准输入会重定向到/dev/null，并且忽略sigup信号，它并不会让进程变为后台任务，所以需要在命令行末尾加上&amp;符号。 2表示标准错误(stderr) ‘&gt;’表示重定向 1表示标准输出(stdout) 0表示标准输入(stdin) 2&gt;&amp;1整个意思是：将标准错误重定向到标准输出，在大于号后面必须加上&amp;符号，否则，它只会重定向到一个名为1的文件。如果没有2&gt;&amp;1，标准输出会以nohup.out文件输出。 程序如何实现守护进程呢 使用umask重设文件创建掩码，通常设为0。这是为了创建文件后，设置更多权限。 调用fork创建子进程，然后父进程退出。fork得来的子进程复制了父进程的环境，最重要的是这样子进程不是session leader了，也不是进程组的组长进程。这是下面setsid的条件。 setsid创建新会话。这样是为了摆脱控制终端。但是这样子进程就成为了新session的session leader，而只有session leader才能控制终端。假如它打开一个终端设备文件，比如/dev/console，就有可能控制终端。所以也有人会在此时再次fork来保证进程不是session leader，从而没有可能控制终端。还有一种避免取得控制终端的方式是：open后面加上O_NOCTTY参数，比如int fd = open(“/dev/console”,O_NOCTTY); 更改当前工作目录到根目录。这个其实只要你的当前工作目录不会被卸载就行。 关闭不再需要的文件描述符 有些可能会将0，1，2重定向到/dev/null，使标准输入输出错误无效。 但是，还留下几个问题 fork之后，父进程退出，子进程脱离了控制终端吗？如果脱离了，那为什么还要setsid呢？如果没有脱离，子进程已经不是session leader了，而只有session leader才能控制终端。 终端退出时，发生了什么，何时发送signup信号 参考资料：http://stackoverflow.com/questions/881388/what-is-the-reason-for-performing-a-double-fork-when-creating-a-daemonhttp://stackoverflow.com/questions/10932592/why-fork-twice/16655124#16655124http://www.win.tue.nl/~aeb/linux/lk/lk-10.htmlhttp://stackoverflow.com/questions/32780706/does-linux-kill-background-processes-if-we-close-the-terminal-from-which-it-hashttp://blog.csdn.net/ithomer/article/details/9288353《UNIX环境高级编程》]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一个简单的makefile编写教程]]></title>
    <url>%2F2016%2F07%2F15%2Fmake-tutorial%2F</url>
    <content type="text"><![CDATA[最近在学习编写一个简单的web server，用到了makefile。 翻译资料： http://www.cs.colby.edu/maxwell/courses/tutorials/maketutor/ 官方文档： http://www.gnu.org/software/make/manual/make.html#Makefile-Contents Makefiles是一种简单的组织代码编写方式。这个教程不仅仅是对make用法的一个初浅的探讨，也可以作为初学者的指南，可以给小到中型项目创建自己的makefiles文件。 比如有以下三个文件： #hellomake.c 12345678#include &lt;hellomake.h&gt;int main() &#123; // call a function in another file myPrintHelloMake(); return(0);&#125; #hellofunc.c 123456789#include &lt;stdio.h&gt;#include &lt;hellomake.h&gt;void myPrintHelloMake(void) &#123; printf("Hello makefiles!\n"); return;&#125; #helomake.h 12345/*example include file*/void myPrintHelloMake(void); 通常，你将执行下面的命令来编译这些代码： gcc -o hellomake hellomake.c hellofunc.c -I. 这里编译了两个c文件，命名了可执行文件hellomake。-I.的意思是包含在当前目录(.)下的hellomake.h文件。典型的测试／修改／debug的方法是在终端用向上箭头来回到你最近使用的编译命令，所以你不得不每次都这样用，特别是一旦你增加了一些c文件。 不幸的事，这种编译方法有两个弊端。第一，如果你丢了编译命令或者换了电脑，你不得不从零输入，效率极低。第二，如果你只是修改了一个c文件，每次都要把它们重新编译也是耗时间和效率低的。所以，是时候看看我们用一个makefile来解决这些问题了。 你可以创建一个最简单的makefile，如下：12hellomake: hellomake.c hellofunc.c gcc -o hellomake hellomake.c hellofunc.c -I. 如果你把上面命令输入到一个文件叫Makefile活着makefile，然后在命令行输入make，它将会执行你在makefile文件里写的编译命令。注意到make没有参数。而且，把文件列表放到：后面，make知道如果任何一个文件改变了，规则hellomake都需要被执行。此刻，你已经解决了问题一，避免重复用键盘上的向上箭头来寻找你最近使用的编译命令。但是，仅仅改变最近编译项，系统仍然效率不高。 一个非常重要需要注意的是在gcc命令前面有一个tab，这是在任何命令开始前都是必需的，否则make会很不开心。 为了效率更高一点，让我们试试下面的makefile：12345CC=gccCFLAGS=-I.hellomake: hellomake.o hellofunc.o $(CC) -o hellomake hellomake.o hellofunc.o -I. 所以现在我们已经定义了一些常量CC和CFLAGS。这些都是特殊的常量，告诉make我们想如何编译文件hellomake.c和hellofunc.c。尤其是，宏指令CC是是c编译程序，而CFLAGS是传给编译命令的标记列表。把目标文件－hellomake.o和hellofunc.o－放入依赖列表和规则中，make知道首先应该编译.c版本文件，然后建立可执行文件hellomake。 对于大部分小型项目来说用这种makefile足够了。但是，还有一件事漏掉了：头文件的包含。如果你打算修改hellomake.h文件，例如，make将不会重新编译.c文件，虽然它们是必需的。为了解决这个，我们需要告诉make所有的.c文件都依赖某个.h文件。我们可以通过写一个简单的规则，加到makefile里面来实现它。 123456789CC=gccCFLAGS=-I.DEPS = hellomake.h%.o: %.c $(DEPS) $(CC) -c -o $@ $&lt; $(CFLAGS)hellomake: hellomake.o hellofunc.o gcc -o hellomake hellomake.o hellofunc.o -I. 第一个新添加的是宏命令DEPS，设置.c文件依赖的.h文件。然后我们定义了一个规则应用于所有以.o结尾的文件。规则是：.o文件依赖.c文件，.h文件包含在DEPS宏命令中；创建.o文件，make必须用CC宏命令定义的编译器编译.c文件。-c标记是建立目标文件，-o $@表示把编译的输出放到:左边名字的文件中，而$&lt;是依赖列表中的第一项，而宏命令CFLAGS正如上面所说的。 最终的简化，用特别宏命令$@和$^，分别表示:左边和右边，分别使以上编译规则更加通用。在下面的例子中，所有包含文件应当在DEPS列出，所有目标文件应当在OBJ中列出。12345678910CC=gccCFLAGS=-I.DEPS = hellomake.hOBJ = hellomake.o hellofunc.o %.o: %.c $(DEPS) $(CC) -c -o $@ $&lt; $(CFLAGS)hellomake: $(OBJ) gcc -o $@ $^ $(CFLAGS) 所以要是我们想把.h文件放入include目录，源代码放入src目录，一些本地库文件放入lib目录会怎么样呢？再者，有时候我们能隐藏那些烦人的到处都是的.o文件吗？答案是，当然可以！随后的makefile定义了include和lib目录的路径，并且把object文件放到src目录下的obj子目录。也有一个宏命令定义了任何你想要包含的库文件，比如math库文件-lm。这个makefile应该放在src目录本地。注意到，也包含了一个清理源代码和object目录的规则make clean。.PHONY规则使make命令不会生成一个名字叫clean的文件。1234567891011121314151617181920212223242526IDIR =../includeCC=gccCFLAGS=-I$(IDIR)ODIR=objLDIR =../libLIBS=-lm_DEPS = hellomake.hDEPS = $(patsubst %,$(IDIR)/%,$(_DEPS))_OBJ = hellomake.o hellofunc.o OBJ = $(patsubst %,$(ODIR)/%,$(_OBJ))$(ODIR)/%.o: %.c $(DEPS) $(CC) -c -o $@ $&lt; $(CFLAGS)hellomake: $(OBJ) gcc -o $@ $^ $(CFLAGS) $(LIBS).PHONY: cleanclean: rm -f $(ODIR)/*.o *~ core $(INCDIR)/*~ 现在你有了一个完美的makefile，可以修改管理小到中型软件工程。你可以增加多个规则到makefile；甚至创建规则调用规则。想获取更多关于makefiles和make方法的信息，可以到官网GNU Make Manual查看。]]></content>
      <categories>
        <category>c</category>
      </categories>
      <tags>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[好用的工具ctags]]></title>
    <url>%2F2016%2F06%2F24%2Fctags%2F</url>
    <content type="text"><![CDATA[参考资料http://www.cnblogs.com/feisky/archive/2012/02/07/2341932.htmlhttp://blog.csdn.net/alexdboy/article/details/3871707 用vim查看代码的时候能够用上 ctags的功能：扫描指定的源文件，找出其中所包含的语法元素，并将找到的相关内容记录下来。大部分的linux系统上都自带有这个工具，而我的mac上虽然也有自带的，但是却不好用，连version都没有，所以得自己安装一个官方的。 从官网上下载：http://ctags.sourceforge.net/ 现在版本是5.8然后安装： &gt; ./configure &gt; make &gt; make installmac自带的地址在/usr/bin/ctags，而自己安装的在/usr/local/bin/ctags，替换下，这样普通用户也能用了。 可以用ctags –list-languages 查看能识别哪些语言 用法： 首先，生成标签文件，一般在根目录下，使用命令ctags -R . -R表示recursive，递归,为当前目录及其子目录中的文件生成标签文件。最后一个.表示在当前目录 运行完当前目录会多一个文件tags，就是索引文件。 然后用vim打开文件，ctrl+]找到光标所在位置的标签定义的地方，ctrl+t 回到跳转之前的标签处。 比如打开a.php，里面有个search函数，定义在b.php，这时可以把光标移到search处，键盘执行ctrl+]，这时会在当前窗口打开b.php，并且光标处在function search一行，执行ctrl+t，回到上个位置。 注意：此时运行vim，必须在&quot;tags&quot;文件所在的目录下运行。 否则，运行它会找不到&quot;tags&quot;文件，而需要在vim中用&quot;:set tags=&quot;命令设定&quot;tags&quot;文件的路径。 对于一个稍微大点的项目，你可能在任何一个目录下打开vim， 这时在.vimrc中增加一行：set tags=tags;/ 告诉vim在当前目录找不到tags文件时请到上层目录查找，一直往上级目录，直到找到tags文件为止。 这在阅读c代码尤为有用]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何翻墙]]></title>
    <url>%2F2016%2F06%2F12%2FgreatWall%2F</url>
    <content type="text"><![CDATA[为了使用google搜索和英文资料。 我所了解的有三种方式： 1. 购买vpn，不过它会代理你的所有网络请求 2. 使用蓝灯(lantern)，免费，但是不稳定，而且也是会代理浏览器所有请求 3. 自己搭建翻墙代理服务器，关键可以设置哪些使用代理，哪些直接连接，这样就可以同时使用公司vpn 我现在基本上用的就是第三种： 首先得购买一台国外的服务器，开启了22端口； 然后本地开启一个ssh工具，连接到国外服务器。mac上使用的是ssh工具时issh软件，浏览器用chrome，安装SwitchyOmega插件如图：打开issh工具，填入所购买服务器的ip，账号密码，还有浏览器插件代理的本地端口，图上为8081 最后设置浏览器，连接到本地ssh服务，选择socks5，如图： 使用SwitchyOmega，可以设置很多规则，来让浏览器访问哪些域名通过代理，哪些是直接连接。]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[php从mysql取出int数据，变成了string]]></title>
    <url>%2F2016%2F05%2F10%2Fmysql-driver%2F</url>
    <content type="text"><![CDATA[php与mysql交互 参考资料： http://stackoverflow.com/questions/1197005/how-to-get-numeric-types-from-mysql-using-pdo#answer-1197041http://zhangxugg-163-com.iteye.com/blog/1894990http://dengxi.blog.51cto.com/4804263/1748965http://blog.ulf-wendel.de/2008/pdo_mysqlnd-the-new-features-of-pdo_mysql/ 以前一直没注意到php从mysql取出来的数据都是string类型，无论是主键int id还是float。因为php是弱类型的语言，所以其实这也没多大关系。但是这引申出php所使用的mysql驱动等问题。 首先，php是如何与mysql交互的。PHP通过某种api（其实就是扩展），基于某种驱动或lib库与mysql server连接通信。 api有三种：mysql,mysqli和pdo。 其中mysql扩展已经不被建议使用，它将在5.5被废弃，而在php7中被去除。 驱动有两种：libmysqlclient(MySQL client server library )和mysqlnd(MySQL native driver )。 在5.3之前，默认使用的都是libmysql.从5.3开始mysqlnd已经内置于php源代码中，并且官方强烈建议使用这个驱动，只要在编译的时候加上就行了，比如：./configure --with-mysqli=mysqlnd --with-pdo-mysql=mysqlnd --with-mysql=mysqlnd。 而从5.4开始，三种api的驱动默认都将为mysqlnd，所以编译的时候不需要指定驱动了，比如：./configure --with-mysqli --with-pdo-mysql --with-mysql。 可以用下面两张图表示：5.3之前 5.3之后 更多对mysqlnd的介绍，参考官方手册http://php.net/manual/zh/book.mysqlnd.php 如果使用的是旧的libmysql，那没办法，得不到mysql数据的类型，都会被转换为string。而从5.3开始使用mysqlnd驱动，就可得到，但是使用mysql扩展还是会被转换成string。通过mysqli的MYSQLI_OPT_INT_AND_FLOAT_NATIVE参数，例如： 1234567&lt;?php $mysqli = new mysqli('127.0.0.1', 'root', '', 'test'); $query = "select * from test_int"; $mysqli-&gt;options(MYSQLI_OPT_INT_AND_FLOAT_NATIVE, 1); $result = $mysqli-&gt;query($query); $info = $result-&gt;fetch_array(); var_dump($info); 而通过pdo，例如： 1234567&lt;?php $pdo = new PDO('mysql:host=127.0.0.1;dbname=test', 'root', ''); $pdo-&gt;setAttribute(PDO::ATTR_EMULATE_PREPARES, false); $pdo-&gt;setAttribute(PDO::ATTR_STRINGIFY_FETCHES, false); foreach ($pdo-&gt;query('select * from test_int') as $row) &#123; var_dump($row);&#125; ATTR_EMULATE_PREPARES默认为true，需要指定；而ATTR_STRINGIFY_FETCHES默认就为false。 需要注意的是：decimal类型的数据，即使有了以上的配置，依然还是输出为string类型。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[flush privilege 本意]]></title>
    <url>%2F2016%2F04%2F19%2Fflush%2F</url>
    <content type="text"><![CDATA[官方文档 http://dev.mysql.com/doc/refman/5.7/en/privilege-changes.html 什么时候用flush privilege？它的作用是什么？为什么要用？翻译了mysql 5.7的官方文档7.2.6节 从字面上看，flush privilege意为刷新权限，以前只是光用这个命令，没有去想这条命令的意义。 当启动mysqld之后，它将所有的权限表内容读进内存中。在那时候，在内存中的表就对控制访问生效了。 如果你用账户管理命令例如grant,revoke,set password, rename user等非直接的修改权限表，mysql服务端会注意到这些改变，并且立即再次的把权限表加载进内存。 如果你用命令例如insert,update,delete直接修改权限表，权限改表将不会生效直到重启服务或者告诉它重载权限表。如果你直接修改了权限表，但是忘记重载了，你的改表将不起作用直到重启服务。这可能导致你疑惑为什么你的改变看起来没有任何不同。 为了告诉服务端重载权限表，运行一个flush-privileges操作。这可以通过发出一个flush privileges声明或者执行一个mysqladmin flush-privileges或者mysqladmin reload命令来完成。 权限表被重载后将会对每一个存在的客户端连接生效，如下： 表和列权限改变会对客户端的下一次请求生效 数据库权限改变在下一次客户端执行use db_name声明后生效 注意 客户端应用可能缓存数据库名称；因此，在没有明确改变一个不同的数据库或者刷新权限情况下，这个影响可能不明显。 对于已连接的客户端，全局的权限和密码不受影响。这些改变只对以后的连接有效。 如果服务端加了–skip-grant-tables选项启动，它将不会读取权限表和执行任何访问控制。任何人都可以连接并且做任何事，这是不安全的。因此为了服务端能开始读取表，使访问检查有效，flush privileges刷新权限吧。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>翻译</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常见算法排序]]></title>
    <url>%2F2016%2F04%2F07%2Fsort%2F</url>
    <content type="text"><![CDATA[几种常用的算法php实现。 冒泡排序 冒泡排序(bubble sort)是一种交换排序，基本思想是：两两比较相邻纪录的关键字，如果反序则交换，直到没有反序的记录为止。(注意：是相邻) 时间复杂度为O(n^2) 代码如下： 123456789101112131415161718192021222324252627&lt;?phpfunction swap(&amp;$a, &amp;$b)&#123; $t = $a; $a = $b; $b = $t; &#125;function bubble($array)&#123; $length = count($array); $t = ''; $flag = true; for ( $i = 0; $i &lt; $length &amp;&amp; $flag; ++$i) &#123; $flag = false; for ( $j = $length-1; $j &gt;= $i; $j-- ) &#123; if (!isset($array[$j+1])) continue; if ( $array[$j] &gt; $array[$j+1]) &#123; swap($array[$j], $array[$j+1]); $flag = true; &#125; &#125; &#125; return $array;&#125; 简单选择排序 简单选择排序法(simple selection sort)就是通过n-i次关键字间的比较，从n-i+1个记录中选出关键字最小的记录，并和第i(1&lt;=i&lt;=n)个记录交换之。 时间复杂度为O(n^2) 代码如下： 12345678910111213141516171819202122232425262728&lt;?phpfunction swap(&amp;$a, &amp;$b)&#123; $t = $a; $a = $b; $b = $t; &#125;function selectSort($array)&#123; $length = count($array); $min = ''; for ( $i= 0; $i&lt;$length; ++$i) &#123; $min = $i; for ( $j = $i+1; $j &lt; $length; ++$j) &#123; if ( $array[$min] &gt; $array[$j]) &#123; $min = $j; &#125; &#125; if ( $i != $min ) &#123; swap($array[$i], $array[$min]); &#125; &#125; return $array;&#125; 插入排序 直接插入排序(straight insertion sort)，基本操作是将一个记录插入到已经排好序的有序表中，复杂度为O(n^2)，因而，插入排序不适合对于数据量比较大的排序应用。但是，如果需要排序的数据量很小，例如，量级小于千，那么插入排序还是一个不错的选择。描述如下 从第一个元素开始，该元素可以认为已经被排序 取出下一个元素，在已经排序的元素序列中从后向前扫描 如果该元素（已排序）大于新元素，将该元素移到下一位置 重复步骤3，直到找到已排序的元素小于或者等于新元素的位置 将新元素插入到该位置后 重复步骤2~5 代码如下： 123456789101112131415161718&lt;?phpfunction insertSort($array)&#123; $length = count($array); $tmp = ''; for ($i=1; $i&lt;$length; ++$i) &#123; if ($array[$i] &lt; $array[$i-1]) &#123; $tmp = $array[$i]; for ($j = $i-1; $j &gt; -1 &amp;&amp; $array[$j] &gt; $tmp; --$j) &#123; $array[$j+1] = $array[$j]; &#125; $array[$j+1] = $tmp; &#125; &#125; return $array;&#125; 希尔排序 希尔排序(shell sort)，不稳定排序。 代码如下，增量为n/2： 123456789101112131415161718&lt;?phpfunction shellSort($array)&#123; $length = count($array); for ($gap = $length &gt;&gt; 1; $gap &gt; 0; $gap &gt;&gt;= 1) &#123; for ( $i = $gap; $i &lt; count($array); ++$i ) &#123; $tmp = $array[$i]; for ( $j = $i - $gap; $j &gt;= 0 &amp;&amp; $array[$j] &gt; $tmp; $j -= $gap ) &#123; $array[$j+$gap] = $array[$j]; &#125; $array[$j+$gap] = $tmp; &#125; &#125; return $array;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浮点数几个易错点]]></title>
    <url>%2F2016%2F04%2F05%2Ffloat%2F</url>
    <content type="text"><![CDATA[参看资料: 浮点数指南：http://floating-point-gui.de/ (后面我会翻译)php官方文档：http://php.net/manual/zh/language.types.float.phphttp://php.net/manual/zh/language.types.integer.php#language.types.integer.castinghttp://php.net/manual/zh/language.types.type-juggling.php 先来看个例子eg1. 1234&lt;?php$n = "19.99";print intval($n * 100).chr(10);print intval(strval($n*100)); 得出来的结果是：1998和1999 另外一个例子eg2. 12&lt;?phpecho (int) ((0.1+0.7) * 10); 结果是：7 官方文档给出的警告是： 决不要将未知的分数强制转换为int类型，这样有时会导致不可预料的结果。 在例子1中，$n与100相乘后被转换为了浮点数，实际上是1998.99999999999984368059813278E1，强制转换为整数后就为1998. 例子2也是，未转换前的结果实际是7.9999999999999991118…，强制转换后为7. 所以正如官网上所说: 永远不要相信浮点数精确到了最后一位，也永远不要直接比较俩浮点数是否相等。 比如下面的例子eg3. 1234&lt;?php$x = 8 - 6.4;$y = 1.6;var_dump($x == $y); 结果并不相等，因为$x实际已经不是1.6了，而是1.5999999…. var_dump只是给你显示最近的数1.6]]></content>
      <categories>
        <category>php</category>
      </categories>
      <tags>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux下删除文件，空间不释放]]></title>
    <url>%2F2016%2F03%2F28%2Frm%2F</url>
    <content type="text"><![CDATA[14年9月写在csdn上 某一天，程序写日志把磁盘给写满了。原因一是程序有死循环，写日志太多了；二是即使用rm把文件删掉了，也没释放空间。 要讨论的就是第二个原因。 我们来简单重现下： 1，写一个test 1234567&lt;?php$a = '111'; $f = fopen('1.txt', 'a+'); while(1)&#123; fwrite($f, $a); sleep(1);&#125; 执行这个程序，它会在本地产生一个1.txt文件，且会一直往里面写。 2，使用ps命令查看，会有进程 18214 8184 0 21:43 pts/0 00:00:00 php test.php 3，我们把1.txt文件删除，会发现8214这个进程还存在 4， 使用lsof -p 8214命令查看其打开的文件，在最后一行会看见：12COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEphp 8214 xxxxx 3u REG 202,1 1896 248330 /home/xxxxx/1.txt (deleted) 发现其还在写入，SIZE还在不断上升，why? 这是因为： 当进程打开了某个文件时，只要该进程保持打开该文件，即使将其删除，它依然存在于磁盘中。这意味着，进程并不知道文件已经被删除，它仍然可以向打开该文件时提供给它的文件描述符进行读取和写入。除了该进程之外，这个文件是不可见的，因为已经删除了其相应的目录索引节点。 5，只能删掉该进程 当然，现在写日志都是按时间来新建文件的，而不是一直往一个文件里写。所以，一般也不会出现这种情况。 参考: （lsof命令详解）http://www.cnblogs.com/ggjucheng/archive/2012/01/08/2316599.html http://blog.163.com/aprilthirty60@126/blog/static/88613578201282703952163/]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于int(M)后面的参数]]></title>
    <url>%2F2016%2F03%2F25%2Fmysql-int%2F</url>
    <content type="text"><![CDATA[参看官方文档：http://dev.mysql.com/doc/refman/5.6/en/numeric-type-attributes.htmlhttp://stackoverflow.com/questions/7552223/int11-vs-intanything-else 在mysql中，int存储需要占用4个字节，无论存的是324123，还是1，与存储数字大小无关。 有符号时，最小值为-2147483648(注意这里是11位显示宽度),最大值为2147483648(此处为10位显示宽度);无符号时（unsigned），最小值为0，最大值为4294967295(注意这里是10位显示宽度)。 在mysql创建表中，大家可以发现，假如不指定int的长度时，默认是11。为什么是11呢，不是12，不是10？ 这是因为默认mysql会设置为每种类型的‘最长’值长度，比如上面可以看到，有符号类型的int最大显示宽度是11位(有个负号)，所以是11。假如你勾选了unsigned，即无符号类型，则为10。 再看看M的意思，官方文档说明是‘display width’显示宽度。原文‘MySQL supports an extension for optionally specifying the display width of integer data types in parentheses following the base keyword for the type.’ 从字面上看，好像是我存个int(4)，它就只能显示4位数字。其实不然，文档上说‘The display width does not constrain the range of values that can be stored in the column. Nor does it prevent values wider than the column display width from being displayed correctly.’，它不是为了限制字段值的存储范围，也不是为了限制那些超过该列指定宽度值的可显示位数。也就是说，设定了int(4)，还是能够存储12345的数字，也能存储数字1。它是为了在值不足M位时左边补足用的，有另外一个参数叫zerofill，默认不指定，则不足M位数时，左补空格；指定了，则补0。比如设置了int(4) zerofill，存储12，mysql会在左边补足0，成为‘0012’；没有设置zerofill，则为‘ 12’。这里要注意的是，在mysql的cli命令行中，是不用显示宽度的，除非是设置了zerofill，所以一般我们看不到那些补足的空格，但是其他的客户端程序可以。这里面php连接获取值为什么不是‘ 12’，我也不知道，还需要再研究，可能是php做了trim。可以参看https://blogs.oracle.com/jsmyth/entry/what_does_the_11_mean 还可以发现，mysql最大可以设置的M为255，不知道为什么。。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kafka-0.9.0]]></title>
    <url>%2F2016%2F03%2F23%2Fkafka-0-9-0%2F</url>
    <content type="text"><![CDATA[原文：http://kafka.apache.org/documentation.html 自己翻译的kafka官方文档（哈哈），持续更新中。。。 开始介绍kafka是一个分布式的(distributed)，分区的(partitioned)，可复制的(replicated) commit log 服务。它提供了作为一个消息系统的常用功能，但又有独一无二的设计。 什么意思呢？ 首先，让我们回顾一些基本的消息术语： kafka维持消息流分类的称作topics. 我们称处理发布消息到kafka topic的为producers. 我们称处理从topics中订阅并且处理已发布的消息流为consumers. 所以，以一个高层次来说，producers通过网络发送消息给kafka集群，集群轮流把它们提供给consumers，如下图： 客户端和服务器之间的交流是以一个单一，高性能，跨语言的tcp协议完成。我们为kafka提供了一个java客户端，但是客户端可以是很多其他语言。 topics 和 logs 让我们首先投入到kafka提供的高级抽象概念－topic 一个topic就是一个种类或者是已发布消息的名称。对于每一个topic，kafka集群(cluster)维持一个分区日志如下图： 每一区都是一系列顺序的，不可改变的消息，消息被连续添加到一个commit log。在分区里的消息都被赋予一个序列id号称作offset，在相应区里面是唯一的。 在一个可以配置的时间段里，kafka保留所有已发布的消息，无论它们是否被消费。例如，如果日志保留时间设置为2天，那么一个消息在发布后的两天内对于消费者是有效的，之后它将会被丢弃从而释放空间。在数据大小方面而言，kafka的性能持续有效，所以保留大量数据没有问题。 事实上，在日志中以每一个消费者的方式保留的唯一元数据是消费者的位置，称作“offset”。这个偏移量由消费者控制：当消费者读消息的时候将线性推进它的偏移量，但是事实上该位置由消费者控制，它可以以任何顺序消费消息。例如，一个消费者可以重置到一个旧的偏移量重新执行。 这些混合的特征意味着kafka消费者非常廉价，它们可以在集群或者其他消费者之间来或去，而没有太多影响。例如，当一些现存的消费者在消费一些主题内容时，你可以用我们的命令行工具来“tail”出这些内容而不会改变什么。 在日志服务中的分区有以下几个目的：首先，它们允许日志按大小比例适应每一个服务器。每一个分区必须适应绑定它的服务器，但是一个主题可能有很多分区，所以它可以随意处理很多数据。第二，它们以相似的单位行动，跟多的是以位。 Distribution 分布式 日志分区分布在kafka集群中的各个服务器上，每一个服务器处理来自一串分区的请求和数据。为了容错，每一个分区会在配置数量的服务器间复制。 每一个分区都有一个服务器作为“leader”－领导者，0或多个服务器当作“followers”－追随者。领导者处理所有来自分区的读和写请求，而追随者被动的从领导者那复制。如果领导者失败了，其中一个追随者将自动成为领导者。（这里有一个疑问，是随机一个follower称为leader吗？）在集群内，每一个服务器在一些分区中扮演一个领导者，而在其他分区中扮演一个追随者，所以可以平衡运行。 Producers 生产者 生产者们发布数据到它们选择的主题里。生产者在主题里有责任选择消息分配到哪个分区里。这可以在仅仅一个循环内进行平衡加载，或者根据某些语义分区函数完成（根据消息中的一些key）。更多分区用法在第二章。 Consumers 消费者 传统消息有2个模块：queuing和publish-subscribe。在一个队列里，一个消费者池从一个服务器中读取消息，然后消息到达它们中的一个；而在publish-subscribe模式中，消息被广播到所有消费者中。kafka提出一个单一的消费者抽象概念，概括了这2个模块－consumer group消费组 消费者用消费组名称作标签，每一个发布到主题的消息会被转发给订阅消费组中的消费实例。消费实例可以是单独进程，或者单独机器。 如果所有的消费实例都属于同个消费组，那么这就像是一个传统的队列在各个消费者间负载均衡。 如果所有的消费实例都属于不同的消费组，那么这就像是pub-sub模块，所有消息广播到所有消费者中。 更通常的，但是，我们发现topics主题有小数目的consumer groups消费群体，用于每个“logical subscriber”逻辑订阅者。每一组由许多可扩展和容错的消费实例组成，就是pub-sub语义上是消费群中的订阅者而不是一个单一的进程。 kafka也比传统消息系统更强的排序保证。 一个传统队列在服务器上顺序保留了消息，如果多个消费者从队列里消费，那么服务器会顺序处理保存的消息。但是，虽然服务器顺序分发消息，但是消息还是被异步转发给消费者，所以它们可能不是顺序到达不同的消费者。这明显意味着，消息的顺序性在并行消费面前失效了。消息系统经常通过一个“exclusive consumer”独家消费的概念来解决这个问题，即只允许一个进程从服务器消费，但是这意味着在进程中没有并行。 一个2个服务器的kafka集群，用2个消费群组绑定了4个分区(p0-p3)。消费群A有2个消费实例，消费群B有4个。 kafka在这方面做的更好。通过一个在主题中的并行(parallelism)概念－分区，kafka不仅可以保证顺序，而且还可以在消费进程池里面负载均衡。这个通过赋予消费群里的消费者主题分区实现，在一个组里面每一个分区被一个消费者消费。通过这个，我们保证消费者是分区里的唯一读取者并且顺序消费数据。所以有很多这样的分区仍在很多消费者实例中负载均衡。但是要注意，在一个消费群里面不可能有比分区更多的消费实例。 kafka只在一个分区内提供全序消息，而不是在分类里的分区之间。对于大部分应用来说，预分区通过key分区数据的能力已经足够了。但是，如果你请求一个全序消息，这只能在一个只有一个分区的分类里实现，虽然这意味着一个消费者处理一个消费群。 Guarantees 保证 高级kafka给出以下保证： 生产者发送消息到一个指定的分类分区将会被顺序添加。那就是说，如果消息m1和m2被同样的生产者发送，m1先发送，然后m1将会比m2低一点偏移，在日志中出现的更早。 一个消费实例顺序看到在日志中存储的消息。 对于一个分类冗余因子n，我们将容忍n-1个服务器丢失提交给日志的信息。 更多这些保证的详细信息会在文档的设计部分给出。 使用案例以下是一些apache kafka常见使用案例的描述。要查看这些领域的更多概述，请看这个blog. messaging消息传递 作为一个传统消息代理的替代者，kafka运作的很好。消息代理基于很多种原因使用（从数据生产者中解耦，缓存还没处理的消息等等）。与大部分消息系统对比，kafka有更好的吞吐量，内置分区，冗余和容错机制，使得它能够很好的置身于大规模消息处理的应用中。 以我们的经验，消息传递使用通常相当于低吞吐量，但是端对端低延时，基于kafka提供的高持久保证。 在这个领域，kafka可以比得上传统的消息系统比如ActiveMQ或者RabbitMQ。 网站行为轨迹 kafka的最初用途是可以重建一个用户的行为轨迹线作为一组实时的发布－订阅feed。这意味着网站活动（比如pv，搜索，或者其他可获得的用户行为）会以每个行为类型一个topic分类的发布到中央topic。这些feed被一系列用途使用，包括实时进程、实时监控、加载进hadoop或者离线数据仓库系统做离线处理和报告。 活跃的轨迹通常包含了高容量的每个用户pv产生的活跃信息。 Metrics度量 kafka经常被用来运转中监控数据，这需要从分布式应用中，生产集中运转中的数据feed，然后汇总统计。 日志聚合 很多朋友用kafka作为日志聚合的一个解决替代方案。典型的，日志聚合线下收集物理日志文件，然后把它们放入一个集中的地方（一个文件系统或者HDFS）来处理。kafka理论上远离了文件细节，给了一个更干净的文件抽象概念，甚至数据作为信息流。这对多种数据源和分布式数据消费有着低延迟和更好的支持。相比于日志中心系统比如scribe和flume，kafka同样提供高性能，强持久冗余保证和更低的端对端延迟。 流式处理 很多用户都是最终阶段处理那些从分类消费而来的未经处理的数据，然后汇总，丰富，或者转换进新的kafka分类作进一步的消费。例如一个文章推荐处理流程可能是先从rss feed流中爬文章内容，然后发布到’articles’分类中；更进一步的处理可能是规范化或者对内容去重，扔到一个放干净文章内容的分类里；最后一步可能是匹配这些内容给相关用户。这创建了一个有别于个别分类的实时数据流曲线图。Storm和Samza是实现这些转换的流行框架。 事件源 事件源是一种状态改变以时间顺序记录的一种应用设计方式。用这种方式，kafka以非常大的存储日志数据支持使的它成为一个应用极好的后端。 日志提交 kafka可以以一种外在的日志提交为分布式系统服务。这个日志帮助在节点之间复制数据，和作为一种预同步机制为那些失败节点恢复数据。kafka的这个log compaction特点帮助支持了这个用例。在这个用法上kafka和Apache BookKeeper项目类似。 快速开始这部分指导假定你是从新开始，没有kafka或者zookeeper数据。 第一步：下载源代码 下载0.9.0.0版本，然后解压它。 &gt; tar -xzf kafka_2.11-0.9.0.0.tgz &gt; cd kafka_2.11-0.9.0.0 第二步：启动服务 kafka用了zookeeper，所以你需要首先启动zookeeper服务。你可以用kafka包里面的简单脚本来启动一个快速简便的单一节点zookeeper实例。 &gt; bin/zookeeper-server-start.sh config/zookeeper.properties [2013-04-22 15:01:37,495] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig) … 现在启动kafka服务： &gt; bin/kafka-server-start.sh config/server.properties [2013-04-22 15:01:47,028] INFO Verifying properties (kafka.utils.VerifiableProperties) [2013-04-22 15:01:47,051] INFO Property socket.send.buffer.bytes is overridden to 1048576 (kafka.utils.VerifiableProperties)… 第三步：创建一个分类 让我们创建一个名叫”test”的分类，仅有一个分区和复制： &gt; bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test 现在我们可以看见这个分类，如果执行了列出分类的命令： &gt; bin/kafka-topics.sh --list --zookeeper localhost:2181 test 或者不手动创建分类，你可以配置你的服务器，当一个不存在的分类发布时自动创建这个分类。 第四步：发送一些消息 kafka自带一个命令行客户端，这个可以从一个文件或者表格式得到输入，然后作为消息发送到kafka集群。默认的，每一行作为一个单独的消息被送出。 运行生产者，然后输入一些消息进控制台发送到服务器。 &gt; bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test This is a message This is another message 第五步：启动一个消费者 kafka也有一个消费者命令行，将消息转储到标准输出。 &gt; bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning This is a message This is another message 如果你在不同终端运行着以上命令，那么你应当可以输入消息到生产者终端，然后在消费者终端出现这些消息。 所有的命令后工具都有额外的选项；不带参数运行命令将会显示出更多用法的详细信息。 第六步：设置多服务器集群 到目前为止，我们已经执行了一个单一服务器，但是这没什么意思。对于kafka，一个单一服务器仅仅是集群中的一个，所以启动更多的服务器实例将没有太多改变。但是为了感受一下，我们还是扩充我们的集群到3个节点（还是在我们的本地机器上）。 首先我们为每一个broker服务器生成一个配置文件： &gt; cp config/server.properties config/server-1.properties &gt; cp config/server.properties config/server-2.properties 现在编辑这些新的文件，设置如下内容： config/server-1.properties: broker.id=1 port=9093 log.dir=/tmp/kafka-logs-1 config/server-2.properties: broker.id=2 port=9094 log.dir=/tmp/kafka-logs-2 在集群的每一个节点中，这个broker.id是唯一和永久的名字。我们修改了端口和日志目录，因为我们是在相同的机器上运行这些，并且想让服务器都注册到相同的端口，彼此覆盖数据。 我们已经有了zookeeper，我们的单一节点也启动了，所以我们只要启动下面两个新节点： &gt; bin/kafka-server-start.sh config/server-1.properties &amp; ... &gt; bin/kafka-server-start.sh config/server-2.properties &amp; ... 现在创建一个新的具有3个冗余因子的分类： &gt; bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 1 --topic my-replicated-topic 好了，我们有了一个集群，但是我们如何知道每一个broker服务器在干什么呢？]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>kafka</tag>
        <tag>翻译</tag>
      </tags>
  </entry>
</search>
